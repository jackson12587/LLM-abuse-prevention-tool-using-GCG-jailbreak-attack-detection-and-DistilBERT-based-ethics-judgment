import tkinter as tk
from tkinter import scrolledtext, filedialog, messagebox
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import joblib  # âœ… ç”¨äºåŠ è½½ StandardScaler
from transformers import GPT2LMHeadModel, GPT2Tokenizer, pipeline
import re
from stanfordcorenlp import StanfordCoreNLP
from nltk.tree import Tree
import time
import os

# âœ… **è®¾ç½® MLP æ¨¡å‹å’Œ StandardScaler å½’ä¸€åŒ–è·¯å¾„**
mlp_model_path = r"your file"
scaler_path = r"your file"

# âœ… **åˆå§‹åŒ– StanfordCoreNLP**
nlp_path = r'your file'
nlp = StanfordCoreNLP(nlp_path)

# âœ… **åˆå§‹åŒ– GPT-2 è¯­è¨€æ¨¡å‹**
tokenizer_gpt = GPT2Tokenizer.from_pretrained('gpt2')
model_gpt = GPT2LMHeadModel.from_pretrained('gpt2')
model_gpt.eval()

# âœ… **åŠ è½½ DistilBERT æœ‰å®³å†…å®¹åˆ†ç±»å™¨**
classifier_distilbert = pipeline("text-classification", 
                                 model=r"your file", 
                                 tokenizer=r"your file",
                                 device=0)

# âœ… **åŠ è½½ StandardScaler**
scaler = joblib.load(scaler_path)
print(f"âœ… åŠ è½½ StandardScaler å½’ä¸€åŒ–å‚æ•°: {scaler_path}")

# âœ… **å®šä¹‰ MLP åˆ†ç±»æ¨¡å‹**
class MLP(nn.Module):
    def __init__(self):
        super(MLP, self).__init__()
        self.fc1 = nn.Linear(3, 32)
        self.bn1 = nn.BatchNorm1d(32)
        self.relu1 = nn.ReLU()
        self.fc2 = nn.Linear(32, 16)
        self.bn2 = nn.BatchNorm1d(16)
        self.relu2 = nn.ReLU()
        self.fc3 = nn.Linear(16, 2)   
        self.dropout = nn.Dropout(0.1)

    def forward(self, x):
        x = self.relu1(self.bn1(self.fc1(x)))
        x = self.dropout(x)
        x = self.relu2(self.bn2(self.fc2(x)))
        x = self.fc3(x)
        return x

# âœ… **å®‰å…¨åŠ è½½ MLP æ¨¡å‹**
mlp_model = MLP()
mlp_model.load_state_dict(torch.load(mlp_model_path, map_location=torch.device('cpu')))  # âœ… æ˜¾å¼æŒ‡å®šè®¾å¤‡
mlp_model.eval()
print(f"âœ… MLP æ¨¡å‹å·²åŠ è½½: {mlp_model_path}")

# âœ… **å‡½æ•°ï¼šè§£æå¥æ³•æ ‘ï¼Œè®¡ç®—ç‰¹å¾**
def analyze_tree(tree):
    depth = tree.height() - 1
    total_nodes = sum(1 for _ in tree.subtrees())
    leaves = len(tree.leaves())
    non_leaves = total_nodes - leaves
    average_branching_factor = sum(len(subtree) for subtree in tree.subtrees(lambda t: t.height() > 2)) / non_leaves if non_leaves > 0 else 0
    lnr = leaves / total_nodes
    return depth, total_nodes, leaves, average_branching_factor, lnr

# âœ… **å‡½æ•°ï¼šè®¡ç®— Perplexity**
def calculate_perplexity(sentence, model, tokenizer):
    encodings = tokenizer(sentence, return_tensors='pt')
    input_ids = encodings.input_ids
    with torch.no_grad():
        outputs = model(input_ids, labels=input_ids)
        loss = outputs.loss
    perplexity = torch.exp(loss)
    return perplexity.item()

# âœ… **GCG åˆ†ç±»å‡½æ•°**
def classify_text(text):
    parse_result = nlp.parse(text)
    tree = Tree.fromstring(parse_result)
    depth, total_nodes, leaves, average_branching_factor, lnr = analyze_tree(tree)
    perplexity = calculate_perplexity(text, model_gpt, tokenizer_gpt)

    # **å½’ä¸€åŒ–è¾“å…¥æ•°æ®**
    input_data = np.array([[lnr, average_branching_factor, perplexity]])
    input_data = scaler.transform(input_data)
    input_tensor = torch.tensor(input_data, dtype=torch.float32)

    # **MLP æ¨ç†**
    with torch.no_grad():
        output = mlp_model(input_tensor)
        probs = F.softmax(output, dim=1)
        predicted_class = torch.argmax(probs, dim=1).item()

    # **DistilBERT è¿›è¡Œæœ‰å®³å†…å®¹åˆ†ç±»**
    bert_result = classifier_distilbert([text])[0]
    bert_label = "harmful" if bert_result['label'] == 'LABEL_1' else "safe"
    bert_confidence = bert_result['score']

    # **ğŸ§ è¾“å‡ºè°ƒè¯•ä¿¡æ¯åˆ° GUI**
    result_text = (
        f"ğŸ§ å¥å­: {text}\n"
        f"ğŸ“Š ç‰¹å¾: lnr={lnr:.4f}, abf={average_branching_factor:.4f}, p={perplexity:.2f}\n"
        f"ğŸ” Logits: {output.numpy()}\n"
        f"ğŸ”¹ softmax è®¡ç®—å: safe={probs[0][0]:.4f}, gcg={probs[0][1]:.4f}\n"
        f"ğŸ›‘ GCG é¢„æµ‹ç±»åˆ«: {'safe' if predicted_class == 0 else 'gcg'}\n"
        f"âš ï¸ DistilBERT é¢„æµ‹: {bert_label}ï¼ˆç½®ä¿¡åº¦: {bert_confidence:.4f}ï¼‰\n"
        f"------------------------------\n"
    )
    
    output_textbox.insert(tk.END, result_text)

    return "safe" if predicted_class == 0 else "gcg", bert_label, bert_confidence

# âœ… **å•ä¸ªæ–‡æœ¬å¤„ç†**
def process_text():
    input_text = input_textbox.get("1.0", tk.END).strip()
    if not input_text:
        return

    output_textbox.delete("1.0", tk.END)
    
    for sentence in input_text.split("\n"):
        classify_text(sentence)

# âœ… **æ‰¹é‡å¤„ç†æ–‡ä»¶**
def process_file():
    file_path = filedialog.askopenfilename(filetypes=[("CSV files", "*.csv"), ("Excel files", "*.xlsx")])
    if not file_path:
        return

    try:
        if file_path.endswith('.csv'):
            df = pd.read_csv(file_path, encoding='utf-8')
        elif file_path.endswith('.xlsx'):
            df = pd.read_excel(file_path)
        else:
            messagebox.showerror("é”™è¯¯", "åªæ”¯æŒ CSV æˆ– Excel æ–‡ä»¶")
            return
    except Exception as e:
        messagebox.showerror("æ–‡ä»¶è¯»å–é”™è¯¯", str(e))
        return

    if 'sentence' not in df.columns:
        messagebox.showerror("é”™è¯¯", "æ–‡ä»¶ä¸­å¿…é¡»åŒ…å«'sentence'åˆ—")
        return

    # **æ‰¹é‡åˆ†ç±»**
    results = []
    for sentence in df['sentence']:
        gcg_result, bert_label, bert_confidence = classify_text(sentence)
        results.append([gcg_result, bert_label, round(bert_confidence, 4)])

    # **æ·»åŠ ç»“æœåˆ—**
    df['GCG åˆ†ç±»'] = [r[0] for r in results]
    df['DistilBERT åˆ†ç±»'] = [r[1] for r in results]
    df['DistilBERT ç½®ä¿¡åº¦'] = [r[2] for r in results]

    # **ä¿å­˜ç»“æœ**
    output_dir = r"your file"
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, os.path.basename(file_path))

    if file_path.endswith('.csv'):
        df.to_csv(output_path, index=False, encoding='utf-8')
    elif file_path.endswith('.xlsx'):
        df.to_excel(output_path, index=False)

    messagebox.showinfo("å®Œæˆ", f"å¤„ç†å®Œæˆï¼Œæ–‡ä»¶å·²ä¿å­˜è‡³: {output_path}")

# âœ… **åˆ›å»º GUI**
root = tk.Tk()
root.title("æ–‡æœ¬åˆ†ç±»")
root.geometry("800x600")

input_textbox = scrolledtext.ScrolledText(root, wrap=tk.WORD, width=60, height=10)
input_textbox.grid(row=0, column=0, padx=10, pady=10)

output_textbox = scrolledtext.ScrolledText(root, wrap=tk.WORD, width=60, height=15)
output_textbox.grid(row=1, column=0, padx=10, pady=10)

tk.Button(root, text="åˆ†ç±»", command=process_text).grid(row=2, column=0, padx=10, pady=10)
tk.Button(root, text="ä¸Šä¼ æ–‡ä»¶å¹¶åˆ†ç±»", command=process_file).grid(row=3, column=0, padx=10, pady=10)

root.mainloop()
